{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc170894-1e0c-46b5-9b32-dedbb8cc28b9",
   "metadata": {},
   "source": [
    "# **Report**\n",
    "*Introduction to Artificial Intelligence IN3062*\n",
    "\n",
    "!!! Code must be commented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a8870",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "explain problem domain\n",
    "\n",
    "describe dataset and what is being analysed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdb2c0",
   "metadata": {},
   "source": [
    "### **Testing and Amending the Distribution of the Problem Domain in the Original Dataset**\n",
    "\n",
    "describe the splitting of datatest 2 into a smaller datatest 2 which matches the size of datatest 1 and the other part being used for validation + code to do this\n",
    "\n",
    "show original training  and validation datasets distributions (chart) between occupancy being a binary 0 or 1 + code to find this using pandas\n",
    "\n",
    "describe SMOTE and show how using it balances the training and validation datasets (chart) + code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b898bda",
   "metadata": {},
   "source": [
    "### **Metrics used for AI Models**\n",
    "\n",
    "describe with relevant hyperparameters:\n",
    "\n",
    "\n",
    "CLASSIFICATION::\n",
    "\n",
    "//\n",
    "\n",
    "accuracy = (num. correct predictions) / total predictions\n",
    "\n",
    "proportion of correct predictions over total predictions\n",
    "\n",
    "works well if the dataset is balanced\n",
    "\n",
    "misleading for imbalanced datasets (e.g., 99% accuracy on a dataset with 99% negatives)\n",
    "\n",
    "//\n",
    "\n",
    "precision = (true positives) / ((true positives) + (false positives))\n",
    "\n",
    "proportion of true positive predictions among all positive predictions\n",
    "\n",
    "important when false positives have high costs (e.g., spam detection)\n",
    "\n",
    "//\n",
    "\n",
    "recall = (true positives) / ((true positives) + (false negatives))\n",
    "\n",
    "sensitivity (true positive rate)\n",
    "\n",
    "proportion of true positives among all actual positives\n",
    "\n",
    "crucial when false negatives are costly (e.g., medical diagnoses)\n",
    "\n",
    "//\n",
    "\n",
    "f1-score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "mean of precision and recall\n",
    "\n",
    "a good model has a balanced precision and recall\n",
    "\n",
    "//\n",
    "\n",
    "reciever operating characteristic = area under the curve\n",
    "\n",
    "measures the trade-off between true positive rate (recall) and false positive rate\n",
    "\n",
    "evaluates model performance across all classification thresholds\n",
    "\n",
    "//\n",
    "\n",
    "REGRESSION::\n",
    "\n",
    "//\n",
    "\n",
    "mean absolute error = average absolute difference between predicted and actual values\n",
    "\n",
    "metric for average error\n",
    "\n",
    "//\n",
    "\n",
    "mean squared error = average squared difference between predicted and actual values\n",
    "\n",
    "penalizes larger errors more heavily than mean absolute error\n",
    "\n",
    "//\n",
    "\n",
    "root mean squared error = square root of mean squared error\n",
    "\n",
    "interpretation in the same units as the target variable\n",
    "\n",
    "//\n",
    "\n",
    "r^2 score = proportion of variance in the target variable explained by the model\n",
    "\n",
    "indicates how well the model fits the data\n",
    "\n",
    "//"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2ba15",
   "metadata": {},
   "source": [
    "### **Baseline Model Performance**\n",
    "\n",
    "code for very basic perception model and what results it produced\n",
    "\n",
    "map the confusion matrix\n",
    "\n",
    "graph metrics of the baseline and model and explain\n",
    "\n",
    "show hyperparameter tweaking of baseline model and describe changes in metrics from results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f1aee",
   "metadata": {},
   "source": [
    "### **Chosen Models and Pre-Processing Methods**\n",
    "\n",
    "describe the models to be used (Both classification and regression models as we have a dataset with both non-real and real data)\n",
    "\n",
    "discuss the models strengths and weaknesses for our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Method 1**\n",
    "\n",
    "code + hyperparameter descriptions\n",
    "\n",
    "tests + metric results + hyperparameter tweaking\n",
    "\n",
    "repeat a couple of times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fc98d",
   "metadata": {},
   "source": [
    "### **Method 2**\n",
    "\n",
    "code + hyperparameter descriptions\n",
    "\n",
    "tests + metric results + hyperparameter tweaking\n",
    "\n",
    "repeat a couple of times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c2b6c",
   "metadata": {},
   "source": [
    "### **Method 3**\n",
    "\n",
    "code + hyperparameter descriptions\n",
    "\n",
    "tests + metric results + hyperparameter tweaking\n",
    "\n",
    "repeat a couple of times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccb3ef",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "which method performed the best\n",
    "\n",
    "what was gained in the trade offs for each one and how much did that benefit the model\n",
    "\n",
    "what were the hyperparameters which made a big difference to the different models for each method\n",
    "\n",
    "state which model overall was the most performant in forming a correct output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
